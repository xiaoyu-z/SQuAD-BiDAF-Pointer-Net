{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionCell(RNNCell):\n",
    "    def __init__(self, cell, memory, mask=None, controller=None, mapper=None, input_keep_prob=1.0, is_train=None):\n",
    "        \"\"\"\n",
    "        Early fusion attention cell: uses the (inputs, state) to control the current attention.\n",
    "\n",
    "        :param cell:\n",
    "        :param memory: [N, M, m]\n",
    "        :param mask:\n",
    "        :param controller: (inputs, prev_state, memory) -> memory_logits\n",
    "        \"\"\"\n",
    "        self._cell = cell\n",
    "        self._memory = memory\n",
    "        self._mask = mask\n",
    "        self._flat_memory = flatten(memory, 2)\n",
    "        self._flat_mask = flatten(mask, 1)\n",
    "        if controller is None:\n",
    "            controller = AttentionCell.get_linear_controller(True, is_train=is_train)\n",
    "        self._controller = controller\n",
    "        if mapper is None:\n",
    "            mapper = AttentionCell.get_concat_mapper()\n",
    "        elif mapper == 'sim':\n",
    "            mapper = AttentionCell.get_sim_mapper()\n",
    "        self._mapper = mapper\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._cell.state_size\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._cell.output_size\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        with tf.variable_scope(scope or \"AttentionCell\"):\n",
    "            memory_logits = self._controller(inputs, state, self._flat_memory)\n",
    "            sel_mem = softsel(self._flat_memory, memory_logits, mask=self._flat_mask)  # [N, m]\n",
    "            new_inputs, new_state = self._mapper(inputs, state, sel_mem)\n",
    "            return self._cell(new_inputs, state)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_double_linear_controller(size, bias, input_keep_prob=1.0, is_train=None):\n",
    "        def double_linear_controller(inputs, state, memory):\n",
    "            \"\"\"\n",
    "\n",
    "            :param inputs: [N, i]\n",
    "            :param state: [N, d]\n",
    "            :param memory: [N, M, m]\n",
    "            :return: [N, M]\n",
    "            \"\"\"\n",
    "            rank = len(memory.get_shape())\n",
    "            _memory_size = tf.shape(memory)[rank-2]\n",
    "            tiled_inputs = tf.tile(tf.expand_dims(inputs, 1), [1, _memory_size, 1])\n",
    "            if isinstance(state, tuple):\n",
    "                tiled_states = [tf.tile(tf.expand_dims(each, 1), [1, _memory_size, 1])\n",
    "                                for each in state]\n",
    "            else:\n",
    "                tiled_states = [tf.tile(tf.expand_dims(state, 1), [1, _memory_size, 1])]\n",
    "\n",
    "            # [N, M, d]\n",
    "            in_ = tf.concat([tiled_inputs] + tiled_states + [memory], axis=2)\n",
    "            out = double_linear_logits(in_, size, bias, input_keep_prob=input_keep_prob,\n",
    "                                       is_train=is_train)\n",
    "            return out\n",
    "        return double_linear_controller\n",
    "\n",
    "    @staticmethod\n",
    "    def get_linear_controller(bias, input_keep_prob=1.0, is_train=None):\n",
    "        def linear_controller(inputs, state, memory):\n",
    "            rank = len(memory.get_shape())\n",
    "            _memory_size = tf.shape(memory)[rank-2]\n",
    "            tiled_inputs = tf.tile(tf.expand_dims(inputs, 1), [1, _memory_size, 1])\n",
    "            if isinstance(state, tuple):\n",
    "                tiled_states = [tf.tile(tf.expand_dims(each, 1), [1, _memory_size, 1])\n",
    "                                for each in state]\n",
    "            else:\n",
    "                tiled_states = [tf.tile(tf.expand_dims(state, 1), [1, _memory_size, 1])]\n",
    "\n",
    "            # [N, M, d]\n",
    "            in_ = tf.concat([tiled_inputs] + tiled_states + [memory], axis=2)\n",
    "            out = linear(in_, 1, bias, squeeze=True, input_keep_prob=input_keep_prob, is_train=is_train)\n",
    "            return out\n",
    "        return linear_controller\n",
    "\n",
    "    @staticmethod\n",
    "    def get_concat_mapper():\n",
    "        def concat_mapper(inputs, state, sel_mem):\n",
    "            \"\"\"\n",
    "\n",
    "            :param inputs: [N, i]\n",
    "            :param state: [N, d]\n",
    "            :param sel_mem: [N, m]\n",
    "            :return: (new_inputs, new_state) tuple\n",
    "            \"\"\"\n",
    "            return tf.concat(axis=1, values=[inputs, sel_mem]), state\n",
    "        return concat_mapper\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sim_mapper():\n",
    "        def sim_mapper(inputs, state, sel_mem):\n",
    "            \"\"\"\n",
    "            Assume that inputs and sel_mem are the same size\n",
    "            :param inputs: [N, i]\n",
    "            :param state: [N, d]\n",
    "            :param sel_mem: [N, i]\n",
    "            :return: (new_inputs, new_state) tuple\n",
    "            \"\"\"\n",
    "            return tf.concat(axis=1, values=[inputs, sel_mem, inputs * sel_mem, tf.abs(inputs - sel_mem)]), state\n",
    "        return sim_mapper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
